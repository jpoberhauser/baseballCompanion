{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940c2053",
   "metadata": {},
   "source": [
    "## Downloading and Transcribing a Youtube Clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eac08009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "import yt_dlp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eba89cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio(youtube_url, out_dir=\"downloads\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': f'{out_dir}/%(id)s.%(ext)s',\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "        }]\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(youtube_url, download=True)\n",
    "        return f\"{out_dir}/{info['id']}.mp3\", info['id']\n",
    "    \n",
    "def transcribe(audio_path, model_size=\"medium\", output_dir=\"transcripts\"):\n",
    "    model = WhisperModel(model_size, compute_type=\"int8\")\n",
    "    segments, _ = model.transcribe(audio_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    text_chunks = []\n",
    "    for seg in segments:\n",
    "        text_chunks.append({\n",
    "            \"start\": seg.start,\n",
    "            \"end\": seg.end,\n",
    "            \"text\": seg.text\n",
    "        })\n",
    "\n",
    "    output_path = os.path.join(output_dir, os.path.basename(audio_path).replace(\".mp3\", \".txt\"))\n",
    "    with open(output_path, \"w\") as f:\n",
    "        for chunk in text_chunks:\n",
    "            f.write(f\"{chunk['text']}\\n\")\n",
    "\n",
    "    print(f\"Transcription saved to: {output_path}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a56df9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=EKkFOMzwMgc\n",
      "[youtube] EKkFOMzwMgc: Downloading webpage\n",
      "[youtube] EKkFOMzwMgc: Downloading tv client config\n",
      "[youtube] EKkFOMzwMgc: Downloading tv player API JSON\n",
      "[youtube] EKkFOMzwMgc: Downloading ios player API JSON\n",
      "[youtube] EKkFOMzwMgc: Downloading m3u8 information\n",
      "[info] EKkFOMzwMgc: Downloading 1 format(s): 251\n",
      "[download] Destination: /Users/jpoberhauser/Desktop/baseballCompanion/data//EKkFOMzwMgc.webm\n",
      "[download] 100% of   50.77MiB in 00:00:01 at 33.38MiB/s    \n",
      "[ExtractAudio] Destination: /Users/jpoberhauser/Desktop/baseballCompanion/data//EKkFOMzwMgc.mp3\n",
      "Deleting original file /Users/jpoberhauser/Desktop/baseballCompanion/data//EKkFOMzwMgc.webm (pass -k to keep)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/Users/jpoberhauser/Desktop/baseballCompanion/data//EKkFOMzwMgc.mp3',\n",
       " 'EKkFOMzwMgc')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_audio('https://www.youtube.com/watch?v=EKkFOMzwMgc', out_dir = '/Users/jpoberhauser/Desktop/baseballCompanion/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d453ec9",
   "metadata": {},
   "source": [
    "This is example is a 24 minute youtube clip and it gets compeltey transcribed in ~13 minutes using the medium model and in using the small model ~5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29f2e6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription saved to: /Users/jpoberhauser/Desktop/baseballCompanion/data/transcripts/EKkFOMzwMgc.txt\n"
     ]
    }
   ],
   "source": [
    "transcribe('/Users/jpoberhauser/Desktop/baseballCompanion/data/EKkFOMzwMgc.mp3',\n",
    "            model_size=\"small\", \n",
    "            output_dir=\"/Users/jpoberhauser/Desktop/baseballCompanion/data/transcripts/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b14bc06",
   "metadata": {},
   "source": [
    "### Let's generate and store embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad5c1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers faiss-cpu\n",
    "import faiss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f00ab0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c45675c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n"
     ]
    }
   ],
   "source": [
    "# The sentences to encode\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]\n",
    "\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "153a68d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01919569,  0.12008531,  0.15959838, ..., -0.00536285,\n",
       "        -0.08109499,  0.05021335],\n",
       "       [-0.01869035,  0.04151865,  0.0743155 , ...,  0.00486595,\n",
       "        -0.06190439,  0.0318751 ],\n",
       "       [ 0.13650198,  0.08227322, -0.02526161, ...,  0.08762044,\n",
       "         0.03045845, -0.01075751]], shape=(3, 384), dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b8895bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.6660, 0.1046],\n",
      "        [0.6660, 1.0000, 0.1411],\n",
      "        [0.1046, 0.1411, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# [3, 384]\n",
    "\n",
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff1cb23",
   "metadata": {},
   "source": [
    "## compare model.similarity to FAISS\n",
    "\n",
    "* obviously its oerkill to use FAISS for three sentence embeddings, but we will need it for hundreds of thousands of text chunks in a real vectorDB. \n",
    "\n",
    "* just to make sure we get similar results, we run the code below, and indeed, the first sentence is most similar to the second one, and they both give a similairyt of _around_ 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06d04f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [[0 1 2]]\n",
      "Distances: [[0.         0.66808915 1.7908318 ]]\n"
     ]
    }
   ],
   "source": [
    "#### compare to FAISS\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])  # L2 = Euclidean, or use IndexFlatIP for cosine\n",
    "index.add(embeddings)\n",
    "\n",
    "# Query similarity from emb1\n",
    "D, I = index.search(embeddings[0].reshape(1, -1), k=3)\n",
    "\n",
    "print(\"Indices of nearest neighbors:\", I)\n",
    "print(\"Distances:\", D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "def build_vector_index(chunks, video_id, save_dir=\"faiss_index\"):\n",
    "    texts = [c['text'] for c in chunks]\n",
    "    embeddings = model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    faiss.write_index(index, f\"{save_dir}/{video_id}.index\")\n",
    "    with open(f\"{save_dir}/{video_id}_meta.pkl\", \"wb\") as f:\n",
    "        pickle.dump(chunks, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseball-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
